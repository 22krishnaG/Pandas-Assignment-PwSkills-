{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSIGNMENT - 2 Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. List any five functions of the pandas library with execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_csv(): This function is used to read data from a CSV file and create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-01d3b1b1ebf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Example: Reading data from a CSV file and creating a DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example: Reading data from a CSV file and creating a DataFrame\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "head(): This function is used to display the first few rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Gender\n",
      "0   Alice   25  Female\n",
      "1     Bob   30    Male\n",
      "2  Claire   27  Female\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Claire', 'David', 'Eva'],\n",
    "    'Age': [25, 30, 27, 22, 28],\n",
    "    'Gender': ['Female', 'Male', 'Female', 'Male', 'Female']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first 3 rows using head()\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groupby(): This function is used to group the data based on one or more columns and perform aggregate operations on the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "Female    26.666667\n",
      "Male      26.000000\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Claire', 'David', 'Eva'],\n",
    "    'Age': [25, 30, 27, 22, 28],\n",
    "    'Gender': ['Female', 'Male', 'Female', 'Male', 'Female']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group the data based on 'Gender' and calculate the average age for each group\n",
    "grouped_data = df.groupby('Gender')['Age'].mean()\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge(): This function is used to merge two DataFrames based on a common column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID    Name  Age\n",
      "0   2     Bob   25\n",
      "1   3  Claire   30\n",
      "2   4   David   27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the first DataFrame\n",
    "data1 = {\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Claire', 'David']\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Create the second DataFrame\n",
    "data2 = {\n",
    "    'ID': [2, 3, 4, 5],\n",
    "    'Age': [25, 30, 27, 22]\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merge the DataFrames on 'ID'\n",
    "merged_df = pd.merge(df1, df2, on='ID')\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop(): This function is used to remove rows or columns from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age\n",
      "0   Alice   25\n",
      "1     Bob   30\n",
      "2  Claire   27\n",
      "3   David   22\n",
      "4     Eva   28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Claire', 'David', 'Eva'],\n",
    "    'Age': [25, 30, 27, 22, 28],\n",
    "    'Gender': ['Female', 'Male', 'Female', 'Male', 'Female']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop the 'Gender' column from the DataFrame\n",
    "df_without_gender = df.drop('Gender', axis=1)\n",
    "print(df_without_gender)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Given a Pandas DataFrame df with columns 'A', 'B', and 'C', write a Python function to re-index the\n",
    "DataFrame with a new index that starts from 1 and increments by 2 for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can achieve this by using the reset_index() function along with custom logic to re-index the DataFrame with a new index starting from 1 and incrementing by 2 for each row. Here's a Python function that does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C\n",
      "1  10  40  70\n",
      "3  20  50  80\n",
      "5  30  60  90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reindex_dataframe(df):\n",
    "    # Reset the index to get the default numerical index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Create a new index starting from 1 and incrementing by 2\n",
    "    new_index = pd.RangeIndex(start=1, stop=len(df) * 2, step=2)\n",
    "    \n",
    "    # Assign the new index to the DataFrame\n",
    "    df.index = new_index\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'A': [10, 20, 30],\n",
    "    'B': [40, 50, 60],\n",
    "    'C': [70, 80, 90]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Re-index the DataFrame using the function\n",
    "df_reindexed = reindex_dataframe(df)\n",
    "\n",
    "print(df_reindexed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the DataFrame df is re-indexed with a new index starting from 1 and incrementing by 2 for each row. The function reindex_dataframe() takes the input DataFrame, resets the index to get the default numerical index, creates a new index using pd.RangeIndex(), and then assigns the new index to the DataFrame using the .index property. The resulting DataFrame df_reindexed has the desired new index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. You have a Pandas DataFrame df with a column named 'Values'. Write a Python function that\n",
    "iterates over the DataFrame and calculates the sum of the first three values in the 'Values' column. The\n",
    "function should print the sum to the console.\n",
    "For example, if the 'Values' column of df contains the values [10, 20, 30, 40, 50], your function should\n",
    "calculate and print the sum of the first three values, which is 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the sum of the first three values in the 'Values' column of the DataFrame directly without iterating over the DataFrame. Pandas provides efficient vectorized operations that allow us to perform such calculations easily. Here's the updated Python function to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of the first three values in 'Values' column: 60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_sum_of_first_three(df):\n",
    "    # Calculate the sum of the first three values in the 'Values' column\n",
    "    sum_of_first_three = df['Values'].head(3).sum()\n",
    "    \n",
    "    # Print the sum to the console\n",
    "    print(\"Sum of the first three values in 'Values' column:\", sum_of_first_three)\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'Values': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to calculate the sum of the first three values\n",
    "calculate_sum_of_first_three(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the function calculate_sum_of_first_three() takes the input DataFrame df, accesses the 'Values' column using df['Values'], extracts the first three values using .head(3), calculates their sum using .sum(), and then prints the result to the console. The sum of the first three values (10 + 20 + 30) in the 'Values' column is 60, which is displayed as the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Given a Pandas DataFrame df with a column 'Text', write a Python function to create a new column\n",
    "'Word_Count' that contains the number of words in each row of the 'Text' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a new column 'Word_Count' in the DataFrame by applying a custom function to each row of the 'Text' column to count the number of words. You can achieve this using the apply() function along with a lambda function to count words in each row. Here's the Python function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Text  Word_Count\n",
      "0  Hello, this is a sample text.           6\n",
      "1     Python programming is fun!           4\n",
      "2     Data analysis with Pandas.           4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_words_in_text(df):\n",
    "    # Create a new column 'Word_Count' containing the number of words in each row of 'Text' column\n",
    "    df['Word_Count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'Text': ['Hello, this is a sample text.', 'Python programming is fun!', 'Data analysis with Pandas.']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to create the 'Word_Count' column\n",
    "count_words_in_text(df)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the function count_words_in_text() takes the input DataFrame df and applies a lambda function to each row of the 'Text' column using the apply() function. The lambda function splits the text into words using the .split() method and then calculates the number of words using len(). The resulting word count is stored in the new 'Word_Count' column, and the updated DataFrame is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. How are DataFrame.size() and DataFrame.shape() different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame.size() and DataFrame.shape() are two different methods in Pandas that provide different information about a DataFrame:\n",
    "\n",
    "1. DataFrame.size(): This method returns the total number of elements in the DataFrame, i.e., the total number of cells. It calculates the size by multiplying the number of rows with the number of columns. It does not provide the dimensions (number of rows and columns) of the DataFrame but rather the total number of data elements in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame size: 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"DataFrame size:\", df.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this example, the DataFrame df has 3 rows and 3 columns, so the total number of elements (size) is 3 x 3 = 9.\n",
    "\n",
    "> DataFrame.shape(): This method returns a tuple representing the dimensions of the DataFrame. The tuple contains two values: the number of rows and the number of columns, respectively. It provides a quick way to check the shape of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"DataFrame shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n this example, the DataFrame df has 3 rows and 3 columns, so the shape is represented by the tuple (3, 3).\n",
    "\n",
    "In summary, DataFrame.size() returns the total number of elements in the DataFrame (rows x columns), while DataFrame.shape() returns a tuple representing the dimensions (number of rows and columns) of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Which function of pandas do we use to read an excel file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read an Excel file in Pandas, you can use the function pd.read_excel(). This function allows you to read data from an Excel file and create a DataFrame with the data.\n",
    "\n",
    "Here's the syntax for using pd.read_excel():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'file.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-308d32b097cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Read data from an Excel file and create a DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m                 )\n\u001b[0;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mfile_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;31m# We have to let unknown file formats pass through here, as some ancient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\gpu4\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36minspect_format\u001b[1;34m(path, content)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPEEK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'file.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from an Excel file and create a DataFrame\n",
    "df = pd.read_excel('file.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, file.xlsx should be replaced with the name of the Excel file you want to read. The function will read the data from the specified Excel file and create a Pandas DataFrame df containing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. You have a Pandas DataFrame df that contains a column named 'Email' that contains email\n",
    "addresses in the format 'username@domain.com'. Write a Python function that creates a new column\n",
    "'Username' in df that contains only the username part of each email address.\n",
    "The username is the part of the email address that appears before the '@' symbol. For example, if the\n",
    "email address is 'john.doe@example.com', the 'Username' column should contain 'john.doe'. Your\n",
    "function should extract the username from each email address and store it in the new 'Username'\n",
    "column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can achieve this by using the str.split() method along with a lambda function to extract the username part of each email address and create a new 'Username' column in the DataFrame. Here's the Python function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Email     Username\n",
      "0     john.doe@example.com     john.doe\n",
      "1   jane.smith@example.com   jane.smith\n",
      "2  bob.jackson@example.com  bob.jackson\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_username(df):\n",
    "    # Extract the username from each email address using split and lambda function\n",
    "    df['Username'] = df['Email'].apply(lambda x: x.split('@')[0])\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'Email': ['john.doe@example.com', 'jane.smith@example.com', 'bob.jackson@example.com']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to extract the username and create the 'Username' column\n",
    "extract_username(df)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the function extract_username() takes the input DataFrame df and applies a lambda function to each row of the 'Email' column using the apply() function. The lambda function splits each email address using the '@' symbol as the separator and then selects the first part, which is the username. The extracted username is stored in the new 'Username' column, and the updated DataFrame is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. You have a Pandas DataFrame df with columns 'A', 'B', and 'C'. Write a Python function that selects\n",
    "all rows where the value in column 'A' is greater than 5 and the value in column 'B' is less than 10. The\n",
    "function should return a new DataFrame that contains only the selected rows.\n",
    "For example, if df contains the following values:\n",
    "A B C\n",
    "0 3 5 1\n",
    "1 8 2 7\n",
    "2 6 9 4\n",
    "3 2 3 5\n",
    "4 9 1 2\n",
    "\n",
    "Assignment\n",
    "\n",
    "Data Science Masters\n",
    "\n",
    "Your function should select the following rows: A B C\n",
    "1 8 2 7\n",
    "4 9 1 2\n",
    "The function should return a new DataFrame that contains only the selected rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: You can create a new DataFrame by using boolean indexing to select the rows where the value in column 'A' is greater than 5 and the value in column 'B' is less than 10. Here's the Python function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "1  8  2  7\n",
      "2  6  9  4\n",
      "4  9  1  2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def select_rows(df):\n",
    "    # Create a boolean mask based on the condition\n",
    "    mask = (df['A'] > 5) & (df['B'] < 10)\n",
    "    \n",
    "    # Select rows based on the boolean mask\n",
    "    selected_rows = df[mask]\n",
    "    \n",
    "    return selected_rows\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'A': [3, 8, 6, 2, 9],\n",
    "    'B': [5, 2, 9, 3, 1],\n",
    "    'C': [1, 7, 4, 5, 2]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to select rows based on the condition\n",
    "selected_df = select_rows(df)\n",
    "\n",
    "# Print the new DataFrame containing only the selected rows\n",
    "print(selected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the function select_rows() takes the input DataFrame df and creates a boolean mask based on the condition (df['A'] > 5) & (df['B'] < 10), where we check if 'A' is greater than 5 and 'B' is less than 10. The boolean mask is then used to select the rows that satisfy the condition, and the new DataFrame selected_df contains only those selected rows. The desired rows are printed as the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. Given a Pandas DataFrame df with a column 'Values', write a Python function to calculate the mean,\n",
    "median, and standard deviation of the values in the 'Values' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the mean(), median(), and std() functions of the Pandas DataFrame to calculate the mean, median, and standard deviation of the values in the 'Values' column, respectively. Here's the Python function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 30.0\n",
      "Median: 30.0\n",
      "Standard Deviation: 15.811388300841896\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_stats(df):\n",
    "    # Calculate the mean, median, and standard deviation of the 'Values' column\n",
    "    mean_value = df['Values'].mean()\n",
    "    median_value = df['Values'].median()\n",
    "    std_value = df['Values'].std()\n",
    "    \n",
    "    return mean_value, median_value, std_value\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'Values': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to calculate the statistics\n",
    "mean, median, std = calculate_stats(df)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Standard Deviation:\", std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the function calculate_stats() takes the input DataFrame df and calculates the mean, median, and standard deviation of the 'Values' column using the mean(), median(), and std() functions, respectively. The results are then returned from the function, and we print the mean, median, and standard deviation to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. Given a Pandas DataFrame df with a column 'Sales' and a column 'Date', write a Python function to\n",
    "create a new column 'MovingAverage' that contains the moving average of the sales for the past 7 days\n",
    "for each row in the DataFrame. The moving average should be calculated using a window of size 7 and\n",
    "should include the current day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> You can use the rolling() function along with the mean() function to calculate the moving average of the 'Sales' column for the past 7 days, including the current day. Here's the Python function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Sales  MovingAverage\n",
      "0 2023-07-01    100     100.000000\n",
      "1 2023-07-02    120     110.000000\n",
      "2 2023-07-03    110     110.000000\n",
      "3 2023-07-04    130     115.000000\n",
      "4 2023-07-05    140     120.000000\n",
      "5 2023-07-06    120     120.000000\n",
      "6 2023-07-07    150     124.285714\n",
      "7 2023-07-08    130     128.571429\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_moving_average(df):\n",
    "    # Sort the DataFrame by the 'Date' column in ascending order\n",
    "    df.sort_values(by='Date', inplace=True)\n",
    "    \n",
    "    # Calculate the moving average using a window of size 7\n",
    "    df['MovingAverage'] = df['Sales'].rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'Date': ['2023-07-01', '2023-07-02', '2023-07-03', '2023-07-04', '2023-07-05', '2023-07-06', '2023-07-07', '2023-07-08'],\n",
    "    'Sales': [100, 120, 110, 130, 140, 120, 150, 130]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the 'Date' column to datetime type\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Call the function to calculate the moving average\n",
    "calculate_moving_average(df)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this example, the function calculate_moving_average() takes the input DataFrame df, sorts it by the 'Date' column in ascending order, and then calculates the moving average of the 'Sales' column using rolling() with a window of size 7 and mean(). The min_periods=1 argument ensures that the moving average includes the current day even if there are fewer than 7 data points available. The new 'MovingAverage' column is added to the DataFrame, and the updated DataFrame is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. You have a Pandas DataFrame df with a column 'Date'. Write a Python function that creates a new\n",
    "column 'Weekday' in the DataFrame. The 'Weekday' column should contain the weekday name (e.g.\n",
    "Monday, Tuesday) corresponding to each date in the 'Date' column.\n",
    "For example, if df contains the following values:\n",
    "Date\n",
    "0 2023-01-01\n",
    "1 2023-01-02\n",
    "2 2023-01-03\n",
    "3 2023-01-04\n",
    "4 2023-01-05\n",
    "Your function should create the following DataFrame:\n",
    "\n",
    "Date Weekday\n",
    "0 2023-01-01 Sunday\n",
    "1 2023-01-02 Monday\n",
    "2 2023-01-03 Tuesday\n",
    "3 2023-01-04 Wednesday\n",
    "4 2023-01-05 Thursday\n",
    "The function should return the modified DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can achieve this by using the dt accessor in Pandas to access the datetime properties of the 'Date' column and then use the strftime() function to extract the weekday name. Here's the Python function to create the 'Weekday' column in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date    Weekday\n",
      "0 2023-01-01     Sunday\n",
      "1 2023-01-02     Monday\n",
      "2 2023-01-03    Tuesday\n",
      "3 2023-01-04  Wednesday\n",
      "4 2023-01-05   Thursday\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_weekday_column(df):\n",
    "    # Convert the 'Date' column to datetime type\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Create the 'Weekday' column with weekday names\n",
    "    df['Weekday'] = df['Date'].dt.strftime('%A')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to create the 'Weekday' column\n",
    "df = add_weekday_column(df)\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. Given a Pandas DataFrame df with a column 'Date' that contains timestamps, write a Python\n",
    "function to select all rows where the date is between '2023-01-01' and '2023-01-31'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use boolean indexing to select all rows in the DataFrame where the 'Date' column falls within the specified date range. Here's the Python function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date\n",
      "0 2023-01-01\n",
      "1 2023-01-15\n",
      "2 2023-01-20\n",
      "4 2023-01-31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def select_rows_between_dates(df, start_date, end_date):\n",
    "    # Convert the 'Date' column to datetime type\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Create a boolean mask based on the condition\n",
    "    mask = (df['Date'] >= start_date) & (df['Date'] <= end_date)\n",
    "    \n",
    "    # Select rows based on the boolean mask\n",
    "    selected_rows = df[mask]\n",
    "    \n",
    "    return selected_rows\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'Date': ['2023-01-01', '2023-01-15', '2023-01-20', '2023-02-05', '2023-01-31']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to select rows between '2023-01-01' and '2023-01-31'\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-01-31'\n",
    "selected_df = select_rows_between_dates(df, start_date, end_date)\n",
    "\n",
    "# Print the DataFrame containing only the selected rows\n",
    "print(selected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the function select_rows_between_dates() takes the input DataFrame df, converts the 'Date' column to datetime type using pd.to_datetime(), and then creates a boolean mask based on the condition (df['Date'] >= start_date) & (df['Date'] <= end_date), where we check if the 'Date' falls within the specified date range. The boolean mask is then used to select the rows that satisfy the condition, and the new DataFrame selected_df contains only those selected rows. The desired rows falling between '2023-01-01' and '2023-01-31' are printed as the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13. To use the basic functions of pandas, what is the first and foremost necessary library that needs to\n",
    "be imported?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and foremost necessary library that needs to be imported to use the basic functions of Pandas is pandas itself. The library is typically imported with the alias pd, which is a commonly used convention in the Pandas community.\n",
    "\n",
    "To import Pandas, you can use the following import statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once imported, you can access all the functionalities and basic functions of Pandas using the pd alias. This includes creating and manipulating DataFrames, performing data analysis, handling missing data, reading and writing data in various formats (e.g., CSV, Excel), and much more.\n",
    "\n",
    "Remember that before using Pandas, you need to have the library installed in your Python environment. You can install Pandas using pip if you don't have it installed already:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu4",
   "language": "python",
   "name": "gpu4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
